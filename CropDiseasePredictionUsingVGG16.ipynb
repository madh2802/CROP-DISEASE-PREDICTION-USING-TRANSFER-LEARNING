{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madh2802/CROP-DISEASE-PREDICTION-USING-TRANSFER-LEARNING/blob/main/CropDiseasePredictionUsingVGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing necessary libraries"
      ],
      "metadata": {
        "id": "UOBdC3pWQ6KJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "csUefM1y2ANi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing google drive"
      ],
      "metadata": {
        "id": "XXy5ni8ZQHcZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coAOrQjDW9Xh",
        "outputId": "02c81aa1-a3c0-4678-9fea-c97a55eb8d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define input shape and number of classes"
      ],
      "metadata": {
        "id": "zE_W4MLZQOA8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1ALJwrt-2i5m"
      },
      "outputs": [],
      "source": [
        "input_shape = (224, 224, 3)\n",
        "num_classes = 38"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load pre-trained VGG16 model and exclude top layers"
      ],
      "metadata": {
        "id": "lHdZgFOEQWzN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91RVcCMa2i7d",
        "outputId": "48f8547f-b463-407c-998d-372902f48c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add custom top layers for our classification task"
      ],
      "metadata": {
        "id": "cALh9vUIQaKC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8h--FYW62jAF"
      },
      "outputs": [],
      "source": [
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(num_classes, activation='softmax')(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the new model"
      ],
      "metadata": {
        "id": "wabpgjV1Qeew"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mr0WFvJZ2jCX"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=base_model.input, outputs=x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Freeze some of the pre-trained layers"
      ],
      "metadata": {
        "id": "eqBencr7Qhws"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BB1cxGVZ2jPP"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers[:-8]:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile the model"
      ],
      "metadata": {
        "id": "95_pZqksQkwH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A2K_ieNw2jRL"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation for training set"
      ],
      "metadata": {
        "id": "WsIrMamaQmXH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9A8CXphx2jVx"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation for validation and test sets"
      ],
      "metadata": {
        "id": "FMjHI1uVQrsA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YxggK8QP2jep"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data"
      ],
      "metadata": {
        "id": "5JRNYVBzQwBO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRRWNgn02jgl",
        "outputId": "1d97ba44-cbdb-496e-8c3f-ae9b0b4880e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8751 images belonging to 38 classes.\n",
            "Found 10547 images belonging to 38 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dir = '/content/drive/MyDrive/data_distribution_for_SVM/train'\n",
        "test_dir = '/content/drive/MyDrive/data_distribution_for_SVM/test'\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train the model"
      ],
      "metadata": {
        "id": "VK5qTTGORMuD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QnX93x5D3Tfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c0448e-21f0-43c5-de25-fdcab7234e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "273/273 [==============================] - 6681s 24s/step - loss: 2.4346 - accuracy: 0.3666 - val_loss: 1.4416 - val_accuracy: 0.6076\n",
            "Epoch 2/8\n",
            "273/273 [==============================] - 189s 693ms/step - loss: 1.3741 - accuracy: 0.6169 - val_loss: 0.7795 - val_accuracy: 0.7682\n",
            "Epoch 3/8\n",
            "273/273 [==============================] - 223s 817ms/step - loss: 0.8778 - accuracy: 0.7444 - val_loss: 0.5369 - val_accuracy: 0.8435\n",
            "Epoch 4/8\n",
            "273/273 [==============================] - 187s 685ms/step - loss: 0.6454 - accuracy: 0.8104 - val_loss: 0.3896 - val_accuracy: 0.8890\n",
            "Epoch 5/8\n",
            "273/273 [==============================] - 187s 684ms/step - loss: 0.4971 - accuracy: 0.8548 - val_loss: 0.3782 - val_accuracy: 0.8876\n",
            "Epoch 6/8\n",
            "273/273 [==============================] - 226s 830ms/step - loss: 0.4149 - accuracy: 0.8765 - val_loss: 0.2665 - val_accuracy: 0.9193\n",
            "Epoch 7/8\n",
            "273/273 [==============================] - 227s 832ms/step - loss: 0.3141 - accuracy: 0.9046 - val_loss: 0.2448 - val_accuracy: 0.9281\n",
            "Epoch 8/8\n",
            "273/273 [==============================] - 222s 814ms/step - loss: 0.2533 - accuracy: 0.9222 - val_loss: 0.2572 - val_accuracy: 0.9264\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=8,  # Increase the number of epochs\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save trained model"
      ],
      "metadata": {
        "id": "nVXYuKTHRQu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Saved_models/CropDiseasePredictionUsingVGG16.h5')"
      ],
      "metadata": {
        "id": "WFbZX1WhZ1hj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model on the test set"
      ],
      "metadata": {
        "id": "24nJoXFNRZ7s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LzP7O5083XOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34a08fab-a886-4f75-9f58-d2e39887fe9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10547 images belonging to 38 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model accuracy\n"
      ],
      "metadata": {
        "id": "Aj-qeVGaRcOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ib-NID5e3ZrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48db25ac-0163-4cf5-c7da-eed7544b1a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.25772422552108765\n",
            "Test accuracy: 0.9263297915458679\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(test_generator, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing\n"
      ],
      "metadata": {
        "id": "xaw0ZsFEyzCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "678fjYbozL53",
        "outputId": "3cb82446-a5bf-4710-e6fd-2d8a29d9b90c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/Trained_model.h5')"
      ],
      "metadata": {
        "id": "Ka73x8fPzQX2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "# load image\n",
        "image = Image.open('/content/013100cc-af7f-47eb-aaef-d46215549bc6 (1).JPG')\n",
        "\n",
        "# resize image to (224, 224)\n",
        "image = image.resize((224, 224))\n",
        "\n",
        "# convert image to numpy array\n",
        "image_array = np.array(image)\n",
        "\n",
        "# add a batch dimension to the image\n",
        "image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "# make predictions\n",
        "predictions = model.predict(image_array)\n",
        "\n",
        "# get the index of the highest probability\n",
        "predicted_class = np.argmax(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ISIf3UZfyyWa",
        "outputId": "685056cc-7458-4be4-de39-d232a8be9677"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-365e3810b653>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# load image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/013100cc-af7f-47eb-aaef-d46215549bc6 (1).JPG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# resize image to (224, 224)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/013100cc-af7f-47eb-aaef-d46215549bc6 (1).JPG'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = {\n",
        "    0: 'Apple Scab',\n",
        "    1: 'Apple Black Rot',\n",
        "    2: 'Apple Cedar Rust',\n",
        "    3: 'Apple healthy',\n",
        "    4: 'Blueberry healthy',\n",
        "    5: 'Cherry healthy',\n",
        "    6: 'Cherry Powdery Mildew',\n",
        "    7: 'Corn Gray Leaf Spot',\n",
        "    8: 'Corn Common Rust',\n",
        "    9: 'Corn healthy',\n",
        "    10: 'Corn Northern Leaf Blight',\n",
        "    11: 'Grape Black Rot',\n",
        "    12: 'Grape Black Measles',\n",
        "    13: 'Grape Leaf Blight',\n",
        "    14: 'Grape healthy',\n",
        "    15: 'Orange Huanglongbing',\n",
        "    16: 'Peach Bacterial Spot',\n",
        "    17: 'Peach healthy',\n",
        "    18: 'Bell Pepper Bacterial Spot',\n",
        "    19: 'Bell Pepper healthy',\n",
        "    20: 'Potato Early Blight',\n",
        "    21: 'Potato healthy',\n",
        "    22: 'Potato Late Blight',\n",
        "    23: 'Raspberry healthy',\n",
        "    24: 'Soybean healthy',\n",
        "    25: 'Squash Powdery Mildew',\n",
        "    26: 'Strawberry Healthy',\n",
        "    27: 'Strawberry Leaf Scorch',\n",
        "    28: 'Tomato Bacterial Spot',\n",
        "    29: 'Tomato Early Blight',\n",
        "    30: 'Tomato Late Blight',\n",
        "    31: 'Tomato Leaf Mold',\n",
        "    32: 'Tomato Septoria Leaf Spot',\n",
        "    33: 'Tomato Two Spotted Spider Mite',\n",
        "    34: 'Tomato Target Spot',\n",
        "     35: 'Tomato Mosaic Virus',\n",
        "    36: 'Tomato Yellow Leaf Curl Virus',\n",
        "    37: 'Tomato healthy'\n",
        "}\n"
      ],
      "metadata": {
        "id": "QgUIvDcc87IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_name = class_names[predicted_class]\n",
        "print(class_name)\n"
      ],
      "metadata": {
        "id": "paaub1Bn9-Pc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}